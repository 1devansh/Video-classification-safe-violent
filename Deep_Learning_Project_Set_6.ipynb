{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Project Set 6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM+woitQdvA/Ge8iFDDWo8i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1devansh/Video-classification-safe-violent/blob/master/Deep_Learning_Project_Set_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak_zK7IhVpUJ",
        "colab_type": "text"
      },
      "source": [
        "## **Import Files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gab0l9iXaUz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBUFz3RfgE2B",
        "colab_type": "code",
        "outputId": "d597b0ea-2ca0-462c-f02a-0106aa02f299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgJkk5ECJmda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.callbacks import Callback\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, UpSampling2D\n",
        "from keras import backend as K\n",
        "\n",
        "import random\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib.pyplot import imshow, figure\n",
        "import cv2\n",
        "import math\n",
        "\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import *\n",
        "import theano\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INb3Qmsmaeen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, RMSprop, adam\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o3oRcrIi-GQ",
        "colab_type": "code",
        "outputId": "396f1cf4-2b9a-4098-f03a-e8b2a646982a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xnckd0LjvgU",
        "colab_type": "code",
        "outputId": "cf29a4df-72d9-429a-fd8c-7aadb45f51da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /gdrive/My Drive/sem 6 deep Learning/projectDataset/C"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4abvzUtr6L1a",
        "colab_type": "code",
        "outputId": "0fd8ab04-fb8f-4c6a-f056-ee3211e4a454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C_10.mp4  C_12.mp4  C_14.mp4  C_2.mp4  C_4.mp4  C_6.mp4  C_9.mp4\n",
            "C_11.mp4  C_13.mp4  C_1.mp4   C_3.mp4  C_5.mp4  C_8.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFBOCgcCjLcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir projectDatasetimages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL5VcXR8sbms",
        "colab_type": "code",
        "outputId": "1ff82f0b-045b-4d38-ebd2-9d4ad0ff5a8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "cd .."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/sem 6 deep Learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXW-LiCPqKVc",
        "colab_type": "code",
        "outputId": "0cf9da00-edef-48e0-aa78-6445f27e5abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test.mov\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1SXGQf9t3AU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_test = \"/gdrive/My Drive/sem 6 deep Learning/projectDataset/C\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngeWwQCTv3W4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testList = os.listdir(path_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dXowVqOxEFX",
        "colab_type": "code",
        "outputId": "85c0a0e0-e7bd-4fef-f2f1-9c4b312804f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C_10.mp4  C_12.mp4  C_14.mp4  C_2.mp4  C_4.mp4  C_6.mp4  C_8.mp4\n",
            "C_11.mp4  C_13.mp4  C_1.mp4   C_3.mp4  C_5.mp4  C_7.mp4  C_9.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLm0xbu3xKs8",
        "colab_type": "code",
        "outputId": "fad37cb4-edee-4a80-e7dc-b93c23e3ee8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "print(testList)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['C_6.mp4', 'C_7.mp4', 'C_8.mp4', 'C_9.mp4', 'C_10.mp4', 'C_11.mp4', 'C_12.mp4', 'C_13.mp4', 'C_14.mp4', 'C_5.mp4', 'C_4.mp4', 'C_3.mp4', 'C_2.mp4', 'C_1.mp4']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubaz_gSgV04N",
        "colab_type": "text"
      },
      "source": [
        "## **Renaming Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWWl0hnMv1Qw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#renaming files in order\n",
        "i = \"1\"\n",
        "for file in testList:\n",
        "  try:\n",
        "    i = str(i)\n",
        "    final = \"A_\" + i + \".avi\"\n",
        "    \n",
        "    os.rename(file,final)\n",
        "    i = int(i)\n",
        "    i = i+1\n",
        "  except FileNotFoundError:\n",
        "    continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIdpx_lRezRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHgvuj2gV8DL",
        "colab_type": "text"
      },
      "source": [
        "## **Extracting frames from dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dojUwB5Kq8Ss",
        "colab_type": "code",
        "outputId": "e76cda49-a5bb-47fc-b313-5c0bec4390f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "#extracting frames from videos C\n",
        "\n",
        "path = \"/gdrive/My Drive/sem 6 deep Learning/projectDataset/C/\"\n",
        "for file in testList:\n",
        "  videoFile = path + file\n",
        "  print(videoFile)\n",
        "  cap = cv2.VideoCapture(videoFile)\n",
        "  frameRate = cap.get(5) #frame rate\n",
        "  \n",
        "  while(cap.isOpened()):\n",
        "      frameId = cap.get(1) #current frame number\n",
        "      ret, frame = cap.read()\n",
        "      if (ret != True):\n",
        "          break\n",
        "      if (frameId % math.floor(frameRate) == 0):\n",
        "          filename = '/gdrive/My Drive/sem 6 deep Learning/projectDatasetimages/C_' +  str(int(x)) + \".jpg\"\n",
        "          x=x+1\n",
        "          cv2.imwrite(filename, frame)\n",
        "\n",
        "  cap.release()\n",
        "  print (\"Done!\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/C/C_6.mp4\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/C/C_7.mp4\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/C/C_8.mp4\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/C/C_9.mp4\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/C/C_10.mp4\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/C/C_11.mp4\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/C/C_12.mp4\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/C/C_13.mp4\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/C/C_14.mp4\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/C/C_5.mp4\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/C/C_4.mp4\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/C/C_3.mp4\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/C/C_2.mp4\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/C/C_1.mp4\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCALup7ufgQV",
        "colab_type": "code",
        "outputId": "77890f0c-df4b-4cef-b682-e6fbe89632f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "198"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySU9Q4UrrTwU",
        "colab_type": "code",
        "outputId": "921f73ba-2331-489c-ae58-1afc45dd4ed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#extracting frames from videos B\n",
        "\n",
        "path = \"/gdrive/My Drive/sem 6 deep Learning/projectDataset/B/\"\n",
        "for file in testList:\n",
        "  videoFile = path + file\n",
        "  print(videoFile)\n",
        "  cap = cv2.VideoCapture(videoFile)\n",
        "  frameRate = cap.get(5) #frame rate\n",
        "  \n",
        "  while(cap.isOpened()):\n",
        "      frameId = cap.get(1) #current frame number\n",
        "      ret, frame = cap.read()\n",
        "      if (ret != True):\n",
        "          break\n",
        "      if (frameId % math.floor(frameRate) == 0):\n",
        "          filename = '/gdrive/My Drive/sem 6 deep Learning/projectDatasetimages/B_' +  str(int(x)) + \".jpg\";x+=1\n",
        "          cv2.imwrite(filename, frame)\n",
        "\n",
        "  cap.release()\n",
        "  print (\"Done!\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/B/B_1.avi\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/B/B_2.avi\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/B/B_3.avi\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/B/B_4.avi\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/B/B_5.avi\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/B/B_6.avi\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/B/B_7.avi\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/B/B_8.avi\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/B/B_9.avi\n",
            "Done!\n",
            "/gdrive/My Drive/sem 6 deep Learning/projectDataset/B/B_10.avi\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgQJ-d01WDAy",
        "colab_type": "text"
      },
      "source": [
        "## **Resizing new image Dataset(frames)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isapMAiPhAN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_frames = \"/gdrive/My Drive/sem 6 deep Learning/projectDatasetimages\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTmnfcPkg2AS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testFrames = os.listdir(path_frames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSHyHxjDcaB1",
        "colab_type": "code",
        "outputId": "f06c57c1-4acc-4bf8-d0ef-181004a79d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(testFrames))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKZw2vfpfprN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file in testFrames:\n",
        "  \n",
        "  im = Image.open(path_frames+ '/' +file)\n",
        "  img = im.resize((200,200))\n",
        "  \n",
        "  \n",
        "  img.save(path_framesOP +'/'+ file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T33UOvDMWkEA",
        "colab_type": "text"
      },
      "source": [
        "## **Creating Labels for Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaTWzHW15B0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_framesOPa = \"/gdrive/My Drive/sem 6 deep Learning/projectDatasetimagesResized/Safe\"\n",
        "path_framesOPb = \"/gdrive/My Drive/sem 6 deep Learning/projectDatasetimagesResized/Potentially Suspicious\"\n",
        "path_framesOPc = \"/gdrive/My Drive/sem 6 deep Learning/projectDatasetimagesResized/Violent Activity\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2gG5z3lWUzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a1 = os.listdir(path_framesOPa)\n",
        "b1 = os.listdir(path_framesOPb)\n",
        "c1 = os.listdir(path_framesOPc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2I2x34ceuZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaJOK0L1boLB",
        "colab_type": "code",
        "outputId": "7c5f6ea9-b47b-4bbb-f9a4-09d5fd5306c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(len(a1))\n",
        "lena = len(a1)\n",
        "\n",
        "print(len(b1))\n",
        "lenb = len(b1)\n",
        "\n",
        "print(len(c1))\n",
        "lenc = len(c1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53\n",
            "58\n",
            "197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmZUbpVQW32U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelA = []\n",
        "labelB = []\n",
        "labelC = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD3RnhK8WUUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(lena):\n",
        "  labelA.append(0)\n",
        "\n",
        "for i in range(lenb):\n",
        "  labelB.append(1)\n",
        "\n",
        "for i in range(lenc):\n",
        "  labelC.append(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdicwkI4ZJtK",
        "colab_type": "code",
        "outputId": "04a706db-086c-43fa-b335-a0de1d711d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(labelA)\n",
        "print(labelB)\n",
        "print(labelC)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSjssvPpbVgb",
        "colab_type": "code",
        "outputId": "d0718f11-2cac-4d3a-e56a-bdbee437fc61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "afor i in range(308):\n",
        "  if(dire[i].split('_')[0] != labels[i]):\n",
        "    print(\"not same\")\n",
        "\n",
        "print(dire[i].split('_')[0])\n",
        "print(dire[i])\n",
        "print(labels[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C\n",
            "C_99.jpg\n",
            "C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRgm1sgIgHbT",
        "colab_type": "code",
        "outputId": "994212db-ed07-4806-8239-79a2ae22b5de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(path_framesOP + '/' +dire[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/sem 6 deep Learning/projectDatasetimagesResized/A_1.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vm2i7vYgO85",
        "colab_type": "text"
      },
      "source": [
        "## **Modifying Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpbEe-98kQpS",
        "colab_type": "text"
      },
      "source": [
        "### **Modifying dataset for image generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7gS5im1kPWl",
        "colab_type": "code",
        "outputId": "d6914ead-0a7d-4526-9b4f-0f0d4936a46f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "print(dire)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A_1.jpg', 'A_10.jpg', 'A_11.jpg', 'A_12.jpg', 'A_13.jpg', 'A_14.jpg', 'A_15.jpg', 'A_16.jpg', 'A_17.jpg', 'A_18.jpg', 'A_19.jpg', 'A_2.jpg', 'A_20.jpg', 'A_21.jpg', 'A_22.jpg', 'A_23.jpg', 'A_24.jpg', 'A_25.jpg', 'A_26.jpg', 'A_27.jpg', 'A_28.jpg', 'A_29.jpg', 'A_3.jpg', 'A_30.jpg', 'A_31.jpg', 'A_32.jpg', 'A_33.jpg', 'A_34.jpg', 'A_35.jpg', 'A_36.jpg', 'A_37.jpg', 'A_38.jpg', 'A_39.jpg', 'A_4.jpg', 'A_40.jpg', 'A_41.jpg', 'A_42.jpg', 'A_43.jpg', 'A_44.jpg', 'A_45.jpg', 'A_46.jpg', 'A_47.jpg', 'A_48.jpg', 'A_49.jpg', 'A_5.jpg', 'A_50.jpg', 'A_51.jpg', 'A_52.jpg', 'A_53.jpg', 'A_6.jpg', 'A_7.jpg', 'A_8.jpg', 'A_9.jpg', 'B_1.jpg', 'B_10.jpg', 'B_11.jpg', 'B_12.jpg', 'B_13.jpg', 'B_14.jpg', 'B_15.jpg', 'B_16.jpg', 'B_17.jpg', 'B_18.jpg', 'B_19.jpg', 'B_2.jpg', 'B_20.jpg', 'B_21.jpg', 'B_22.jpg', 'B_23.jpg', 'B_24.jpg', 'B_25.jpg', 'B_26.jpg', 'B_27.jpg', 'B_28.jpg', 'B_29.jpg', 'B_3.jpg', 'B_30.jpg', 'B_31.jpg', 'B_32.jpg', 'B_33.jpg', 'B_34.jpg', 'B_35.jpg', 'B_36.jpg', 'B_37.jpg', 'B_38.jpg', 'B_39.jpg', 'B_4.jpg', 'B_40.jpg', 'B_41.jpg', 'B_42.jpg', 'B_43.jpg', 'B_44.jpg', 'B_45.jpg', 'B_46.jpg', 'B_47.jpg', 'B_48.jpg', 'B_49.jpg', 'B_5.jpg', 'B_50.jpg', 'B_51.jpg', 'B_52.jpg', 'B_53.jpg', 'B_54.jpg', 'B_55.jpg', 'B_56.jpg', 'B_57.jpg', 'B_58.jpg', 'B_6.jpg', 'B_7.jpg', 'B_8.jpg', 'B_9.jpg', 'C_1.jpg', 'C_10.jpg', 'C_100.jpg', 'C_101.jpg', 'C_102.jpg', 'C_103.jpg', 'C_104.jpg', 'C_105.jpg', 'C_106.jpg', 'C_107.jpg', 'C_108.jpg', 'C_109.jpg', 'C_11.jpg', 'C_110.jpg', 'C_111.jpg', 'C_112.jpg', 'C_113.jpg', 'C_114.jpg', 'C_115.jpg', 'C_116.jpg', 'C_117.jpg', 'C_118.jpg', 'C_119.jpg', 'C_12.jpg', 'C_120.jpg', 'C_121.jpg', 'C_122.jpg', 'C_123.jpg', 'C_124.jpg', 'C_125.jpg', 'C_126.jpg', 'C_127.jpg', 'C_128.jpg', 'C_129.jpg', 'C_13.jpg', 'C_130.jpg', 'C_131.jpg', 'C_132.jpg', 'C_133.jpg', 'C_134.jpg', 'C_135.jpg', 'C_136.jpg', 'C_137.jpg', 'C_138.jpg', 'C_139.jpg', 'C_14.jpg', 'C_140.jpg', 'C_141.jpg', 'C_142.jpg', 'C_143.jpg', 'C_144.jpg', 'C_145.jpg', 'C_146.jpg', 'C_147.jpg', 'C_148.jpg', 'C_149.jpg', 'C_15.jpg', 'C_150.jpg', 'C_151.jpg', 'C_152.jpg', 'C_153.jpg', 'C_154.jpg', 'C_155.jpg', 'C_156.jpg', 'C_157.jpg', 'C_158.jpg', 'C_159.jpg', 'C_16.jpg', 'C_160.jpg', 'C_161.jpg', 'C_162.jpg', 'C_163.jpg', 'C_164.jpg', 'C_165.jpg', 'C_166.jpg', 'C_167.jpg', 'C_168.jpg', 'C_169.jpg', 'C_17.jpg', 'C_170.jpg', 'C_171.jpg', 'C_172.jpg', 'C_173.jpg', 'C_174.jpg', 'C_175.jpg', 'C_176.jpg', 'C_177.jpg', 'C_178.jpg', 'C_179.jpg', 'C_18.jpg', 'C_180.jpg', 'C_181.jpg', 'C_182.jpg', 'C_183.jpg', 'C_184.jpg', 'C_185.jpg', 'C_186.jpg', 'C_187.jpg', 'C_188.jpg', 'C_189.jpg', 'C_19.jpg', 'C_190.jpg', 'C_191.jpg', 'C_192.jpg', 'C_193.jpg', 'C_194.jpg', 'C_195.jpg', 'C_196.jpg', 'C_197.jpg', 'C_2.jpg', 'C_20.jpg', 'C_21.jpg', 'C_22.jpg', 'C_23.jpg', 'C_24.jpg', 'C_25.jpg', 'C_26.jpg', 'C_27.jpg', 'C_28.jpg', 'C_29.jpg', 'C_3.jpg', 'C_30.jpg', 'C_31.jpg', 'C_32.jpg', 'C_33.jpg', 'C_34.jpg', 'C_35.jpg', 'C_36.jpg', 'C_37.jpg', 'C_38.jpg', 'C_39.jpg', 'C_4.jpg', 'C_40.jpg', 'C_41.jpg', 'C_42.jpg', 'C_43.jpg', 'C_44.jpg', 'C_45.jpg', 'C_46.jpg', 'C_47.jpg', 'C_48.jpg', 'C_49.jpg', 'C_5.jpg', 'C_50.jpg', 'C_51.jpg', 'C_52.jpg', 'C_53.jpg', 'C_54.jpg', 'C_55.jpg', 'C_56.jpg', 'C_57.jpg', 'C_58.jpg', 'C_59.jpg', 'C_6.jpg', 'C_60.jpg', 'C_61.jpg', 'C_62.jpg', 'C_63.jpg', 'C_64.jpg', 'C_65.jpg', 'C_66.jpg', 'C_67.jpg', 'C_68.jpg', 'C_69.jpg', 'C_7.jpg', 'C_70.jpg', 'C_71.jpg', 'C_72.jpg', 'C_73.jpg', 'C_74.jpg', 'C_75.jpg', 'C_76.jpg', 'C_77.jpg', 'C_78.jpg', 'C_79.jpg', 'C_8.jpg', 'C_80.jpg', 'C_81.jpg', 'C_82.jpg', 'C_83.jpg', 'C_84.jpg', 'C_85.jpg', 'C_86.jpg', 'C_87.jpg', 'C_88.jpg', 'C_89.jpg', 'C_9.jpg', 'C_90.jpg', 'C_91.jpg', 'C_92.jpg', 'C_93.jpg', 'C_94.jpg', 'C_95.jpg', 'C_96.jpg', 'C_97.jpg', 'C_98.jpg', 'C_99.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZF-goEslIps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "safe = \"/gdrive/My Drive/sem 6 deep Learning/projectDatasetimagesResized/Safe\"\n",
        "violentActivity = \"/gdrive/My Drive/sem 6 deep Learning/projectDatasetimagesResized/Violent Activity\"\n",
        "Potential = \"/gdrive/My Drive/sem 6 deep Learning/projectDatasetimagesResized/Potentially Suspicious\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LUzD9IvkO3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file in dire:\n",
        "  if file.split('_')[0] == 'A':\n",
        "    im = Image.open(path_framesOP+ '/' +file)\n",
        "    \n",
        "    im.save(safe +'/'+ file)\n",
        "  elif file.split('_')[0] == 'B':\n",
        "    im = Image.open(path_framesOP+ '/' +file)\n",
        "    \n",
        "    im.save(Potential +'/'+ file)\n",
        "  elif file.split('_')[0] == 'C':\n",
        "    im = Image.open(path_framesOP+ '/' +file)\n",
        "    \n",
        "    im.save(violentActivity +'/'+ file)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbTzWdJ5keFr",
        "colab_type": "text"
      },
      "source": [
        "### **Inception model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd6tbfkSwIbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from array import array\n",
        "from __future__ import unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvT1DjoLieoq",
        "colab_type": "code",
        "outputId": "66dbcd51-c725-4115-b51e-110e4f09b200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "base_model=InceptionV3(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
        "x=Dense(512,activation='relu')(x) #dense layer 3\n",
        "preds=Dense(3,activation='softmax')(x) #final layer with softmax activation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue8C_buoieln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Model(inputs=base_model.input,outputs=preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr2uDn2Yieiy",
        "colab_type": "code",
        "outputId": "9ebe52c9-a779-4189-80a2-7cca16c63a98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i,layer in enumerate(model.layers):\n",
        "  print(i,layer.name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_1\n",
            "1 conv2d_1\n",
            "2 batch_normalization_1\n",
            "3 activation_1\n",
            "4 conv2d_2\n",
            "5 batch_normalization_2\n",
            "6 activation_2\n",
            "7 conv2d_3\n",
            "8 batch_normalization_3\n",
            "9 activation_3\n",
            "10 max_pooling2d_1\n",
            "11 conv2d_4\n",
            "12 batch_normalization_4\n",
            "13 activation_4\n",
            "14 conv2d_5\n",
            "15 batch_normalization_5\n",
            "16 activation_5\n",
            "17 max_pooling2d_2\n",
            "18 conv2d_9\n",
            "19 batch_normalization_9\n",
            "20 activation_9\n",
            "21 conv2d_7\n",
            "22 conv2d_10\n",
            "23 batch_normalization_7\n",
            "24 batch_normalization_10\n",
            "25 activation_7\n",
            "26 activation_10\n",
            "27 average_pooling2d_1\n",
            "28 conv2d_6\n",
            "29 conv2d_8\n",
            "30 conv2d_11\n",
            "31 conv2d_12\n",
            "32 batch_normalization_6\n",
            "33 batch_normalization_8\n",
            "34 batch_normalization_11\n",
            "35 batch_normalization_12\n",
            "36 activation_6\n",
            "37 activation_8\n",
            "38 activation_11\n",
            "39 activation_12\n",
            "40 mixed0\n",
            "41 conv2d_16\n",
            "42 batch_normalization_16\n",
            "43 activation_16\n",
            "44 conv2d_14\n",
            "45 conv2d_17\n",
            "46 batch_normalization_14\n",
            "47 batch_normalization_17\n",
            "48 activation_14\n",
            "49 activation_17\n",
            "50 average_pooling2d_2\n",
            "51 conv2d_13\n",
            "52 conv2d_15\n",
            "53 conv2d_18\n",
            "54 conv2d_19\n",
            "55 batch_normalization_13\n",
            "56 batch_normalization_15\n",
            "57 batch_normalization_18\n",
            "58 batch_normalization_19\n",
            "59 activation_13\n",
            "60 activation_15\n",
            "61 activation_18\n",
            "62 activation_19\n",
            "63 mixed1\n",
            "64 conv2d_23\n",
            "65 batch_normalization_23\n",
            "66 activation_23\n",
            "67 conv2d_21\n",
            "68 conv2d_24\n",
            "69 batch_normalization_21\n",
            "70 batch_normalization_24\n",
            "71 activation_21\n",
            "72 activation_24\n",
            "73 average_pooling2d_3\n",
            "74 conv2d_20\n",
            "75 conv2d_22\n",
            "76 conv2d_25\n",
            "77 conv2d_26\n",
            "78 batch_normalization_20\n",
            "79 batch_normalization_22\n",
            "80 batch_normalization_25\n",
            "81 batch_normalization_26\n",
            "82 activation_20\n",
            "83 activation_22\n",
            "84 activation_25\n",
            "85 activation_26\n",
            "86 mixed2\n",
            "87 conv2d_28\n",
            "88 batch_normalization_28\n",
            "89 activation_28\n",
            "90 conv2d_29\n",
            "91 batch_normalization_29\n",
            "92 activation_29\n",
            "93 conv2d_27\n",
            "94 conv2d_30\n",
            "95 batch_normalization_27\n",
            "96 batch_normalization_30\n",
            "97 activation_27\n",
            "98 activation_30\n",
            "99 max_pooling2d_3\n",
            "100 mixed3\n",
            "101 conv2d_35\n",
            "102 batch_normalization_35\n",
            "103 activation_35\n",
            "104 conv2d_36\n",
            "105 batch_normalization_36\n",
            "106 activation_36\n",
            "107 conv2d_32\n",
            "108 conv2d_37\n",
            "109 batch_normalization_32\n",
            "110 batch_normalization_37\n",
            "111 activation_32\n",
            "112 activation_37\n",
            "113 conv2d_33\n",
            "114 conv2d_38\n",
            "115 batch_normalization_33\n",
            "116 batch_normalization_38\n",
            "117 activation_33\n",
            "118 activation_38\n",
            "119 average_pooling2d_4\n",
            "120 conv2d_31\n",
            "121 conv2d_34\n",
            "122 conv2d_39\n",
            "123 conv2d_40\n",
            "124 batch_normalization_31\n",
            "125 batch_normalization_34\n",
            "126 batch_normalization_39\n",
            "127 batch_normalization_40\n",
            "128 activation_31\n",
            "129 activation_34\n",
            "130 activation_39\n",
            "131 activation_40\n",
            "132 mixed4\n",
            "133 conv2d_45\n",
            "134 batch_normalization_45\n",
            "135 activation_45\n",
            "136 conv2d_46\n",
            "137 batch_normalization_46\n",
            "138 activation_46\n",
            "139 conv2d_42\n",
            "140 conv2d_47\n",
            "141 batch_normalization_42\n",
            "142 batch_normalization_47\n",
            "143 activation_42\n",
            "144 activation_47\n",
            "145 conv2d_43\n",
            "146 conv2d_48\n",
            "147 batch_normalization_43\n",
            "148 batch_normalization_48\n",
            "149 activation_43\n",
            "150 activation_48\n",
            "151 average_pooling2d_5\n",
            "152 conv2d_41\n",
            "153 conv2d_44\n",
            "154 conv2d_49\n",
            "155 conv2d_50\n",
            "156 batch_normalization_41\n",
            "157 batch_normalization_44\n",
            "158 batch_normalization_49\n",
            "159 batch_normalization_50\n",
            "160 activation_41\n",
            "161 activation_44\n",
            "162 activation_49\n",
            "163 activation_50\n",
            "164 mixed5\n",
            "165 conv2d_55\n",
            "166 batch_normalization_55\n",
            "167 activation_55\n",
            "168 conv2d_56\n",
            "169 batch_normalization_56\n",
            "170 activation_56\n",
            "171 conv2d_52\n",
            "172 conv2d_57\n",
            "173 batch_normalization_52\n",
            "174 batch_normalization_57\n",
            "175 activation_52\n",
            "176 activation_57\n",
            "177 conv2d_53\n",
            "178 conv2d_58\n",
            "179 batch_normalization_53\n",
            "180 batch_normalization_58\n",
            "181 activation_53\n",
            "182 activation_58\n",
            "183 average_pooling2d_6\n",
            "184 conv2d_51\n",
            "185 conv2d_54\n",
            "186 conv2d_59\n",
            "187 conv2d_60\n",
            "188 batch_normalization_51\n",
            "189 batch_normalization_54\n",
            "190 batch_normalization_59\n",
            "191 batch_normalization_60\n",
            "192 activation_51\n",
            "193 activation_54\n",
            "194 activation_59\n",
            "195 activation_60\n",
            "196 mixed6\n",
            "197 conv2d_65\n",
            "198 batch_normalization_65\n",
            "199 activation_65\n",
            "200 conv2d_66\n",
            "201 batch_normalization_66\n",
            "202 activation_66\n",
            "203 conv2d_62\n",
            "204 conv2d_67\n",
            "205 batch_normalization_62\n",
            "206 batch_normalization_67\n",
            "207 activation_62\n",
            "208 activation_67\n",
            "209 conv2d_63\n",
            "210 conv2d_68\n",
            "211 batch_normalization_63\n",
            "212 batch_normalization_68\n",
            "213 activation_63\n",
            "214 activation_68\n",
            "215 average_pooling2d_7\n",
            "216 conv2d_61\n",
            "217 conv2d_64\n",
            "218 conv2d_69\n",
            "219 conv2d_70\n",
            "220 batch_normalization_61\n",
            "221 batch_normalization_64\n",
            "222 batch_normalization_69\n",
            "223 batch_normalization_70\n",
            "224 activation_61\n",
            "225 activation_64\n",
            "226 activation_69\n",
            "227 activation_70\n",
            "228 mixed7\n",
            "229 conv2d_73\n",
            "230 batch_normalization_73\n",
            "231 activation_73\n",
            "232 conv2d_74\n",
            "233 batch_normalization_74\n",
            "234 activation_74\n",
            "235 conv2d_71\n",
            "236 conv2d_75\n",
            "237 batch_normalization_71\n",
            "238 batch_normalization_75\n",
            "239 activation_71\n",
            "240 activation_75\n",
            "241 conv2d_72\n",
            "242 conv2d_76\n",
            "243 batch_normalization_72\n",
            "244 batch_normalization_76\n",
            "245 activation_72\n",
            "246 activation_76\n",
            "247 max_pooling2d_4\n",
            "248 mixed8\n",
            "249 conv2d_81\n",
            "250 batch_normalization_81\n",
            "251 activation_81\n",
            "252 conv2d_78\n",
            "253 conv2d_82\n",
            "254 batch_normalization_78\n",
            "255 batch_normalization_82\n",
            "256 activation_78\n",
            "257 activation_82\n",
            "258 conv2d_79\n",
            "259 conv2d_80\n",
            "260 conv2d_83\n",
            "261 conv2d_84\n",
            "262 average_pooling2d_8\n",
            "263 conv2d_77\n",
            "264 batch_normalization_79\n",
            "265 batch_normalization_80\n",
            "266 batch_normalization_83\n",
            "267 batch_normalization_84\n",
            "268 conv2d_85\n",
            "269 batch_normalization_77\n",
            "270 activation_79\n",
            "271 activation_80\n",
            "272 activation_83\n",
            "273 activation_84\n",
            "274 batch_normalization_85\n",
            "275 activation_77\n",
            "276 mixed9_0\n",
            "277 concatenate_1\n",
            "278 activation_85\n",
            "279 mixed9\n",
            "280 conv2d_90\n",
            "281 batch_normalization_90\n",
            "282 activation_90\n",
            "283 conv2d_87\n",
            "284 conv2d_91\n",
            "285 batch_normalization_87\n",
            "286 batch_normalization_91\n",
            "287 activation_87\n",
            "288 activation_91\n",
            "289 conv2d_88\n",
            "290 conv2d_89\n",
            "291 conv2d_92\n",
            "292 conv2d_93\n",
            "293 average_pooling2d_9\n",
            "294 conv2d_86\n",
            "295 batch_normalization_88\n",
            "296 batch_normalization_89\n",
            "297 batch_normalization_92\n",
            "298 batch_normalization_93\n",
            "299 conv2d_94\n",
            "300 batch_normalization_86\n",
            "301 activation_88\n",
            "302 activation_89\n",
            "303 activation_92\n",
            "304 activation_93\n",
            "305 batch_normalization_94\n",
            "306 activation_86\n",
            "307 mixed9_1\n",
            "308 concatenate_2\n",
            "309 activation_94\n",
            "310 mixed10\n",
            "311 global_average_pooling2d_1\n",
            "312 dense_1\n",
            "313 dense_2\n",
            "314 dense_3\n",
            "315 dense_4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onx21V_8ieQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers[:20]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[20:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScgFgidyjRbt",
        "colab_type": "code",
        "outputId": "2cfdfab2-afed-49fe-ed9c-a6b3037f48f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory('/gdrive/My Drive/sem 6 deep Learning/projectDatasetimagesResized',\n",
        "                                                 target_size=(200,200),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 308 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4ybHgg4jRYk",
        "colab_type": "code",
        "outputId": "2f33d305-a019-4231-9d9b-f65cbaed96cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy\n",
        "\n",
        "step_size_train=(train_generator.n//train_generator.batch_size) * 3\n",
        "model.fit_generator(generator=train_generator,\n",
        "                   steps_per_epoch=step_size_train,\n",
        "                   epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "308/308 [==============================] - 87s 283ms/step - loss: 0.0911 - accuracy: 0.9854\n",
            "Epoch 2/10\n",
            "308/308 [==============================] - 67s 219ms/step - loss: 0.1208 - accuracy: 0.9784\n",
            "Epoch 3/10\n",
            "308/308 [==============================] - 67s 217ms/step - loss: 0.0285 - accuracy: 0.9956\n",
            "Epoch 4/10\n",
            "308/308 [==============================] - 67s 218ms/step - loss: 0.0109 - accuracy: 0.9968\n",
            "Epoch 5/10\n",
            "308/308 [==============================] - 67s 217ms/step - loss: 0.1205 - accuracy: 0.9873\n",
            "Epoch 6/10\n",
            "308/308 [==============================] - 68s 220ms/step - loss: 0.1188 - accuracy: 0.9850\n",
            "Epoch 7/10\n",
            "308/308 [==============================] - 68s 220ms/step - loss: 0.0086 - accuracy: 0.9981\n",
            "Epoch 8/10\n",
            "308/308 [==============================] - 67s 216ms/step - loss: 0.0228 - accuracy: 0.9963\n",
            "Epoch 9/10\n",
            "308/308 [==============================] - 66s 216ms/step - loss: 0.0054 - accuracy: 0.9986\n",
            "Epoch 10/10\n",
            "308/308 [==============================] - 67s 216ms/step - loss: 0.0043 - accuracy: 0.9987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f2e6e2780b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IeIjE09jRFg",
        "colab_type": "code",
        "outputId": "bfec8c11-e5a9-401d-cc35-ddf366c9e516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.predict()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4Nylz1TjQya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B8SGeofjAEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu89-3ihi_yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkBwiQiXgOVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "immatrixtest = np.array([np.array(Image.open(path_framesOP+ '/' + img)).flatten()\n",
        "for img in dire], 'f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDAe_bSZgN2Z",
        "colab_type": "code",
        "outputId": "bcf85589-990d-420f-a9c3-73faf6e9131d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(immatrixtest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.   0.   0. ...   0.   0.   0.]\n",
            " [  0.   0.   0. ...   0.   0.   0.]\n",
            " [  0.   0.   0. ...   0.   0.   0.]\n",
            " ...\n",
            " [ 89. 103.  88. ...  72.  91.  85.]\n",
            " [ 91. 110.  90. ...  68.  85.  77.]\n",
            " [ 94. 101.  83. ...  65.  87.  84.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93h3l13GiI8m",
        "colab_type": "code",
        "outputId": "904e1d41-317c-4d95-c8fa-e6dd7d17ece6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "\n",
        "print(size(immatrixtest))\n",
        "print(shape(immatrixtest))\n",
        "print(immatrixtest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36960000\n",
            "(308, 120000)\n",
            "[[  0.   0.   0. ...   0.   0.   0.]\n",
            " [  0.   0.   0. ...   0.   0.   0.]\n",
            " [  0.   0.   0. ...   0.   0.   0.]\n",
            " ...\n",
            " [ 89. 103.  88. ...  72.  91.  85.]\n",
            " [ 91. 110.  90. ...  68.  85.  77.]\n",
            " [ 94. 101.  83. ...  65.  87.  84.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mhgB5ndiP8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data, Label = shuffle(immatrixtest, labels, random_state = 2)\n",
        "train_data = [data, Label]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjq7y6qcicTB",
        "colab_type": "code",
        "outputId": "ebadc9fb-69df-4b25-bd92-c2e5ae0ec35f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "img = immatrixtest[24].reshape(200,200,3)\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7769c69240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-iovv46io4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X, y) = (train_data[0], train_data[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsSD5kCsio2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMltcdFoiooh",
        "colab_type": "code",
        "outputId": "0d0ddbc9-fed8-434b-8174-bf95dec5806b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print(y_train)\n",
        "print(X_test)\n",
        "\n",
        "num_train_examples = X_train\n",
        "num_test_examples = X_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['C', 'C', 'C', 'C', 'B', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'B', 'C', 'C', 'A', 'A', 'C', 'C', 'A', 'C', 'C', 'B', 'C', 'A', 'A', 'C', 'A', 'C', 'C', 'B', 'C', 'A', 'C', 'C', 'C', 'C', 'C', 'C', 'A', 'B', 'A', 'C', 'C', 'C', 'C', 'A', 'C', 'C', 'B', 'C', 'C', 'C', 'C', 'C', 'A', 'C', 'C', 'B', 'A', 'C', 'B', 'C', 'C', 'C', 'C', 'C', 'C', 'A', 'C', 'A', 'C', 'C', 'C', 'C', 'C', 'C', 'A', 'B', 'C', 'C', 'C', 'B', 'C', 'B', 'C', 'C', 'C', 'A', 'C', 'C', 'C', 'A', 'C', 'C', 'B', 'A', 'C', 'C', 'B', 'B', 'B', 'B', 'C', 'B', 'A', 'C', 'C', 'B', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'B', 'C', 'B', 'B', 'C', 'C', 'B', 'A', 'C', 'A', 'C', 'C', 'C', 'B', 'C', 'B', 'C', 'C', 'C', 'A', 'C', 'C', 'A', 'C', 'A', 'A', 'A', 'B', 'C', 'C', 'C', 'A', 'C', 'B', 'C', 'A', 'B', 'A', 'C', 'C', 'B', 'C', 'B', 'C', 'C', 'C', 'C', 'B', 'C', 'C', 'B', 'C', 'B', 'C', 'A', 'C', 'C', 'B', 'A', 'B', 'C', 'C', 'C', 'C', 'C', 'A', 'C', 'C', 'C', 'C', 'A', 'B', 'C', 'C', 'B', 'C', 'A', 'C', 'B', 'B', 'B', 'C', 'C', 'A', 'B', 'C', 'C', 'C', 'B', 'C', 'C', 'B', 'C', 'B', 'A', 'C', 'C', 'A', 'B', 'A', 'A', 'C', 'C', 'C', 'C', 'C', 'A', 'A', 'C', 'B', 'A', 'B', 'B', 'C', 'A', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'A']\n",
            "[[ 41.  35.  49. ...  61.  38.  67.]\n",
            " [  0.   0.   0. ...   3.   3.   3.]\n",
            " [  0.   0.   0. ...   0.   0.   0.]\n",
            " ...\n",
            " [ 86.  48.  45. ...  51.  55.  64.]\n",
            " [  0.   0.   0. ...   0.   0.   0.]\n",
            " [ 83.  81.  68. ... 157. 158. 163.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SXkQvt7js_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_channel = 3\n",
        "img_rows, img_columns = 200, 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzkySeVFibxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_columns, img_channel)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_columns, img_channel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqpVREbejjhT",
        "colab_type": "code",
        "outputId": "933fdd99-da37-4e92-de05-2ff46c3ef98a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print(shape(X_train[100, 78]))\n",
        "print(shape(X_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 3)\n",
            "(246, 200, 200, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNgeV7mQjjKH",
        "colab_type": "code",
        "outputId": "6c05d0d3-6ca9-4489-824f-257f1ebdc62a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "Y_train = np_utils.to_categorical(y_train, 3)\n",
        "Y_test = np_utils.to_categorical(y_test, 3)\n",
        "\n",
        "print(Y_train[100])\n",
        "print(shape(Y_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 0.]\n",
            "(246, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltk0o3HPjiqz",
        "colab_type": "code",
        "outputId": "7bb5c3c9-ccda-4ba6-c324-c7ff78044881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "#print(X_train[100,:,:,:])\n",
        "print(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 0, 2, 2, 0, 2, 2, 1, 2, 0, 0, 2, 0, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 0, 1, 0, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 1, 0, 2, 2, 1, 1, 1, 1, 2, 1, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 0, 2, 0, 2, 2, 2, 1, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 0, 1, 2, 2, 2, 0, 2, 1, 2, 0, 1, 0, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 1, 2, 2, 1, 2, 0, 2, 1, 1, 1, 2, 2, 0, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 0, 2, 2, 0, 1, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 1, 0, 1, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQnbKb0JkUJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(y_test)):\n",
        "  if y_test[i] == 'A':\n",
        "    y_test[i] = 0\n",
        "  elif y_test[i] == 'B':\n",
        "    y_test[i] = 1\n",
        "  elif y_test[i] == 'C':\n",
        "    y_test[i] = 2 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohpwZmXLkTpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjNXE-hBWJs-",
        "colab_type": "text"
      },
      "source": [
        "## **Inception Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoiAJ2MHhUwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn-vGICwx9mr",
        "colab_type": "code",
        "outputId": "36dec44c-da43-461f-ad3d-d789e7b9a794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "pre_trained_model = InceptionV3(input_shape = (200,200,3), include_top= False, weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpEDlSoGyjIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCWDJdXUy3yT",
        "colab_type": "code",
        "outputId": "5f38ea4c-243f-40b4-d229-b4892e7c901d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "#x = layers.Flatten()(pre_trained_model.output)\n",
        "#x = layers.Dense(1024, activation = 'relu')(x)\n",
        "#x = layers.Dropout(0.2)(x)\n",
        "#x = layers.Dense(2048)\n",
        "model = pre_trained_model([\n",
        "    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(2048,  activation=tf.nn.softmax)\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-ba5ffd4d1902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m ])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    712\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    713\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0mtensor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conform_to_reference_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m       \u001b[0mx_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mtensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_usage_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_conform_to_reference_input\u001b[0;34m(self, tensor, ref_input)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Dtype handling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompositeTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m       \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    785\u001b[0m       \u001b[0;31m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m       \u001b[0;31m# strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    319\u001b[0m                                          as_ref=False):\n\u001b[1;32m    320\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (<tensorflow.python.keras.layers.core.Dense object at 0x7f772d3c7b00>) with an unsupported type (<class 'tensorflow.python.keras.layers.core.Dense'>) to a Tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ged98JeRBF0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "nb_classes =2\n",
        "nb_epochs = 10\n",
        "img_rows, img_columns = 200, 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2P4tM2yBKh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "nb_classes =52\n",
        "nb_epochs = 10\n",
        "img_rows, img_columns = 200, 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvJc4AFXz8zF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_trained_model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UoTwYQuAq98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_trained_model.fit(X_train, Y_train, batch_size = batch_size, epochs = nb_epochs, verbose = 1, validation_data = (X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ_-Sv5X8Kzi",
        "colab_type": "code",
        "outputId": "1d323a20-6dda-4062-bf6a-467d99d8c57d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "! git remote add origin \"https://github.com/1devansh/Video-classification-safe-violent.git\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amn23m_h8N1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}